# üìñ Explicaci√≥n de Par√°metros del Modelfile

**Documento:** Gu√≠a de Par√°metros de Configuraci√≥n  
**Audiencia:** Ingenieros que necesitan ajustar el modelo  
**√öltima actualizaci√≥n:** 5 de Noviembre 2025  

---

## üìÑ Archivo Principal

El archivo `Modelfile.AztecAI.Professional` contiene toda la configuraci√≥n del modelo personalizado AztecAI.

---

## üèóÔ∏è Estructura del Modelfile

```dockerfile
FROM gpt-oss:20b

# System Prompt (n√∫cleo del comportamiento)
SYSTEM """
[450 l√≠neas de instrucciones]
"""

# Par√°metros de generaci√≥n
PARAMETER temperature 0.7
PARAMETER top_p 0.9
PARAMETER top_k 40
PARAMETER num_ctx 8192
PARAMETER num_predict 2048
PARAMETER repeat_penalty 1.1
PARAMETER seed -1
```

---

## üìä Explicaci√≥n de Cada Par√°metro

### 1. FROM

```dockerfile
FROM gpt-oss:20b
```

**Qu√© hace:** Define el modelo base sobre el cual se construye AztecAI.

**Valor actual:** `gpt-oss:20b`
- Modelo de 20 mil millones de par√°metros
- 40-50 GB de tama√±o
- Equilibrio entre calidad y velocidad

**NO cambiar** a menos que:
- Tengas un modelo base diferente validado
- Hayas probado en staging primero

---

### 2. SYSTEM

```dockerfile
SYSTEM """
[System Prompt Core de 450 l√≠neas]
"""
```

**Qu√© hace:** Define la "personalidad" y comportamiento del modelo.

**Contenido:**
- Identidad de AztecAI
- Formato profesional "Pir√°mide Invertida"
- Guardrails corporativos
- Instrucciones de RAG
- Tono de voz

**Editar solo si:**
- Cambias el comportamiento core del modelo
- Ajustas el formato de respuestas
- Modificas guardrails

**‚ö†Ô∏è CR√çTICO:** Siempre hacer backup antes de modificar.

---

### 3. PARAMETER temperature

```dockerfile
PARAMETER temperature 0.7
```

**Qu√© hace:** Controla la "creatividad" del modelo.

**Rango:** 0.0 a 2.0
- **0.0-0.3:** Muy determinista, respuestas repetitivas
- **0.4-0.7:** Balanceado (RECOMENDADO)
- **0.8-1.2:** M√°s creativo, menos predecible
- **1.3-2.0:** Muy aleatorio, puede incoherentar

**Valor actual:** 0.7 (balanceado)

**Cu√°ndo ajustar:**
- Subir (0.8-0.9): Para tareas creativas (brainstorming, copy marketing)
- Bajar (0.4-0.6): Para tareas t√©cnicas (c√≥digo, n√∫meros, datos)

**Efecto en AztecAI:**
- 0.7 permite respuestas profesionales pero no rob√≥ticas
- Suficiente variedad sin perder consistencia
- Ideal para asistente corporativo

---

### 4. PARAMETER top_p

```dockerfile
PARAMETER top_p 0.9
```

**Qu√© hace:** L√≠mite de probabilidad acumulada (nucleus sampling).

**Rango:** 0.0 a 1.0
- **0.5:** Muy conservador
- **0.9:** Balanceado (RECOMENDADO)
- **1.0:** Considera todas las opciones

**Valor actual:** 0.9

**Relaci√≥n con temperature:**
- `top_p` y `temperature` trabajan juntos
- `top_p 0.9` + `temperature 0.7` = balance √≥ptimo

**Cu√°ndo ajustar:**
- Bajar (0.7-0.8): Si respuestas muy repetitivas
- Subir (0.95): Si necesitas m√°s variedad

---

### 5. PARAMETER top_k

```dockerfile
PARAMETER top_k 40
```

**Qu√© hace:** N√∫mero de tokens candidatos a considerar.

**Rango:** 1 a 100
- **10-20:** Muy limitado
- **40:** Balanceado (RECOMENDADO)
- **80-100:** Muy amplio

**Valor actual:** 40

**Efecto:**
- Limita vocabulario activo en cada paso
- 40 es suficiente para espa√±ol corporativo
- Reduce probabilidad de tokens raros/incorrectos

**Cu√°ndo ajustar:**
- Subir (60-80): Si respuestas muy gen√©ricas
- Bajar (20-30): Si muchos errores o palabras raras

---

### 6. PARAMETER num_ctx

```dockerfile
PARAMETER num_ctx 8192
```

**Qu√© hace:** Tama√±o de la ventana de contexto (tokens).

**Rango:** 512 a 32768 (depende del modelo)
- **2048:** Conversaciones cortas
- **8192:** Balanceado (RECOMENDADO)
- **16384:** Conversaciones muy largas

**Valor actual:** 8192 tokens (‚âà 6,000-7,000 palabras)

**Impacto:**
- **Mayor contexto:**
  - ‚úÖ Recuerda m√°s de la conversaci√≥n
  - ‚úÖ Mejor coherencia en respuestas largas
  - ‚ùå M√°s lento
  - ‚ùå M√°s uso de RAM

- **Menor contexto:**
  - ‚úÖ M√°s r√°pido
  - ‚úÖ Menos RAM
  - ‚ùå Olvida conversaci√≥n anterior
  - ‚ùå Pierde coherencia

**Cu√°ndo ajustar:**
- Subir (16384): Si conversaciones muy t√©cnicas/largas
- Bajar (4096): Si performance es problema

---

### 7. PARAMETER num_predict

```dockerfile
PARAMETER num_predict 2048
```

**Qu√© hace:** M√°ximo de tokens a generar por respuesta.

**Rango:** 128 a 4096
- **256:** Respuestas muy cortas
- **2048:** Balanceado (RECOMENDADO)
- **4096:** Respuestas muy extensas

**Valor actual:** 2048 tokens (‚âà 1,500-1,800 palabras)

**Efecto:**
- L√≠mite superior de longitud de respuesta
- No obliga a generar 2048, es el m√°ximo
- 2048 es suficiente para formato "Pir√°mide Invertida"

**Cu√°ndo ajustar:**
- Subir (3072-4096): Si respuestas se cortan frecuentemente
- Bajar (1024): Si respuestas demasiado largas

---

### 8. PARAMETER repeat_penalty

```dockerfile
PARAMETER repeat_penalty 1.1
```

**Qu√© hace:** Penaliza repetici√≥n de tokens.

**Rango:** 0.5 a 2.0
- **0.8-1.0:** Permite repetici√≥n
- **1.1:** Penalizaci√≥n ligera (RECOMENDADO)
- **1.3-2.0:** Penalizaci√≥n fuerte

**Valor actual:** 1.1

**Efecto:**
- 1.1 reduce repeticiones sin forzar vocabulario artificial
- Evita frases como "y adem√°s, adem√°s, adem√°s..."
- Mantiene naturalidad del lenguaje

**Cu√°ndo ajustar:**
- Subir (1.2-1.3): Si respuestas muy repetitivas
- Bajar (1.0): Si vocabulario muy forzado/raro

---

### 9. PARAMETER seed

```dockerfile
PARAMETER seed -1
```

**Qu√© hace:** Semilla para generaci√≥n aleatoria.

**Valores:**
- **-1:** Aleatorio cada vez (RECOMENDADO)
- **N√∫mero fijo:** Respuestas reproducibles

**Valor actual:** -1 (aleatorio)

**Uso:**
- Producci√≥n: -1 (variedad en respuestas)
- Testing: N√∫mero fijo (reproducibilidad)

**Ejemplo:**
```dockerfile
# Producci√≥n
PARAMETER seed -1

# Testing (respuestas id√©nticas)
PARAMETER seed 42
```

---

## üéØ Configuraciones Preestablecidas

### Configuraci√≥n Actual (Balanceada)

```dockerfile
PARAMETER temperature 0.7
PARAMETER top_p 0.9
PARAMETER top_k 40
PARAMETER num_ctx 8192
PARAMETER num_predict 2048
PARAMETER repeat_penalty 1.1
```

**Ideal para:** Asistente corporativo general

---

### Configuraci√≥n Creativa (Marketing/Contenido)

```dockerfile
PARAMETER temperature 0.8
PARAMETER top_p 0.95
PARAMETER top_k 60
PARAMETER num_ctx 8192
PARAMETER num_predict 2048
PARAMETER repeat_penalty 1.0
```

**Ideal para:** Copywriting, brainstorming, ideas creativas

---

### Configuraci√≥n T√©cnica (C√≥digo/Datos)

```dockerfile
PARAMETER temperature 0.4
PARAMETER top_p 0.8
PARAMETER top_k 30
PARAMETER num_ctx 8192
PARAMETER num_predict 2048
PARAMETER repeat_penalty 1.2
```

**Ideal para:** C√≥digo, an√°lisis t√©cnico, precisi√≥n

---

### Configuraci√≥n Alta Performance (Velocidad)

```dockerfile
PARAMETER temperature 0.7
PARAMETER top_p 0.9
PARAMETER top_k 40
PARAMETER num_ctx 4096    # ‚Üê Reducido
PARAMETER num_predict 1024 # ‚Üê Reducido
PARAMETER repeat_penalty 1.1
```

**Ideal para:** Muchos usuarios concurrentes, respuestas cortas

---

## üîÑ C√≥mo Cambiar Par√°metros

### Opci√≥n 1: Editar Modelfile (Cambio Permanente)

```bash
# 1. Backup del Modelfile actual
cp Modelfile.AztecAI.Professional Modelfile.AztecAI.Professional.backup

# 2. Editar
vim Modelfile.AztecAI.Professional

# 3. Recrear modelo
ollama create aztecai -f Modelfile.AztecAI.Professional

# 4. Probar
ollama run aztecai "¬øQu√© canales tiene TV Azteca?"

# 5. Si funciona, hacer commit
# Si no funciona, restaurar backup
```

---

### Opci√≥n 2: Override en OpenWebUI (Temporal)

```
1. Abrir OpenWebUI
2. Settings ‚Üí Models
3. Seleccionar "aztecai"
4. Advanced Parameters
5. Modificar temporalmente
6. Probar en nueva conversaci√≥n

NO persiste entre reinicios
```

---

## ‚ö†Ô∏è Precauciones

### NO Hacer

‚ùå Cambiar m√∫ltiples par√°metros a la vez
- Dif√≠cil saber qu√© caus√≥ el cambio

‚ùå Valores extremos sin probar
- `temperature 0.0` o `2.0` causan problemas

‚ùå Modificar sin backup
- Siempre respaldar antes de cambiar

‚ùå Cambiar en producci√≥n directamente
- Probar en staging primero

### S√ç Hacer

‚úÖ Cambiar un par√°metro a la vez
‚úÖ Documentar cambios realizados
‚úÖ Probar exhaustivamente
‚úÖ Tener plan de rollback
‚úÖ Validar con usuarios piloto

---

## üß™ Proceso de Prueba

```bash
# 1. Backup
cp Modelfile.AztecAI.Professional Modelfile.backup

# 2. Modificar UN par√°metro
vim Modelfile.AztecAI.Professional

# 3. Recrear modelo
ollama create aztecai -f Modelfile.AztecAI.Professional

# 4. Probar con 10 preguntas diferentes
ollama run aztecai "Pregunta 1"
ollama run aztecai "Pregunta 2"
# ...

# 5. Evaluar:
# - ¬øFormato correcto?
# - ¬øVelocidad aceptable?
# - ¬øCalidad de respuestas?

# 6. Decidir:
# SI funciona mejor ‚Üí Commit y deploy
# NO funciona mejor ‚Üí Restaurar backup
```

---

## üìä Tabla de Troubleshooting

| Problema | Par√°metro | Ajuste |
|----------|-----------|--------|
| Respuestas muy lentas | num_ctx | Bajar a 4096 |
| Se cortan las respuestas | num_predict | Subir a 3072 |
| Respuestas repetitivas | repeat_penalty | Subir a 1.2-1.3 |
| Respuestas muy rob√≥ticas | temperature | Subir a 0.8 |
| Respuestas incoherentes | temperature | Bajar a 0.5-0.6 |
| Vocabulario muy raro | top_k | Bajar a 30 |
| Muy gen√©rico | top_k | Subir a 60 |
| Usa mucha RAM | num_ctx | Bajar a 4096 |

---

## üéì Conceptos Clave

### Temperature vs Top_p vs Top_k

```
Todos controlan "aleatoriedad" pero diferente:

Temperature:
‚îî‚îÄ Ajusta distribuci√≥n de probabilidades
   Valores altos = m√°s aleatorio

Top_p:
‚îî‚îÄ Corta probabilidad acumulada
   Solo considera tokens hasta sumar 0.9 prob

Top_k:
‚îî‚îÄ L√≠mite absoluto de candidatos
   Solo considera los 40 tokens m√°s probables

Mejor pr√°ctica:
Usar los 3 juntos para control fino
```

### Context Window vs Predict Length

```
num_ctx (Context Window):
‚îî‚îÄ Cu√°nto "recuerda" de la conversaci√≥n
   8192 tokens = toda la charla hasta ahora

num_predict (Predict Length):
‚îî‚îÄ Cu√°nto puede "escribir" en una respuesta
   2048 tokens = una respuesta larga

Analog√≠a:
num_ctx = tama√±o de tu libreta de notas
num_predict = cu√°nto puedes escribir en una p√°gina
```

---

## üìù Log de Cambios Recomendado

```markdown
# Historial de Cambios en Par√°metros

## 2025-11-05 - Configuraci√≥n Inicial
- temperature: 0.7
- top_p: 0.9
- top_k: 40
- num_ctx: 8192
- num_predict: 2048
- repeat_penalty: 1.1
- Raz√≥n: Configuraci√≥n balanceada validada en local

## [Futuro] 2025-11-XX - Optimizaci√≥n Performance
- num_ctx: 8192 ‚Üí 4096
- Raz√≥n: Reducir latencia para 50+ usuarios
- Resultado: [Pendiente]
```

---

**Documento creado:** 5 de Noviembre 2025  
**Versi√≥n:** 1.0  
**Mantenido por:** IAA - H√©ctor Romero Pico  

---

*"Entender los par√°metros es entender el modelo."* üéõÔ∏è  
*AztecAI - Documentaci√≥n T√©cnica* üá≤üáΩ

