# üöÄ Instalaci√≥n de AztecAI desde GitHub

**Versi√≥n:** 1.0  
**Fecha:** 6 de Noviembre 2025  
**Repositorio:** https://github.com/MLeon28/TVA  
**Ruta del Modelo:** `AztecAI_Model_V1/`

---

## üìã Descripci√≥n

Este documento explica c√≥mo instalar AztecAI directamente desde el repositorio de GitHub en un servidor de producci√≥n.

---

## ‚ö° Instalaci√≥n R√°pida (M√©todo Recomendado)

### Opci√≥n 1: Instalaci√≥n con un solo comando

```bash
curl -fsSL https://raw.githubusercontent.com/MLeon28/TVA/main/AztecAI_Model_V1/install_from_github.sh | sudo bash
```

Este comando:
1. ‚úÖ Descarga el script de instalaci√≥n
2. ‚úÖ Clona el repositorio completo
3. ‚úÖ Verifica la estructura
4. ‚úÖ Ejecuta el despliegue automatizado
5. ‚úÖ Configura todos los servicios

**Tiempo estimado:** 30-60 minutos  
**Descarga:** ~40-50 GB

---

### Opci√≥n 2: Instalaci√≥n manual paso a paso

Si prefieres m√°s control sobre el proceso:

```bash
# 1. Descargar el script de instalaci√≥n
wget https://raw.githubusercontent.com/MLeon28/TVA/main/AztecAI_Model_V1/install_from_github.sh

# 2. Dar permisos de ejecuci√≥n
chmod +x install_from_github.sh

# 3. Ejecutar el script
sudo ./install_from_github.sh
```

---

## üì¶ ¬øQu√© hace el script de instalaci√≥n?

El script `install_from_github.sh` realiza las siguientes acciones:

### 1. Verificaciones Previas
- ‚úÖ Verifica que se ejecute como root/sudo
- ‚úÖ Verifica el sistema operativo (Ubuntu 22.04 LTS recomendado)
- ‚úÖ Verifica conexi√≥n a internet
- ‚úÖ Verifica espacio en disco (m√≠nimo 100GB)

### 2. Instalaci√≥n de Dependencias
- ‚úÖ Instala Git si no est√° presente
- ‚úÖ Actualiza repositorios del sistema

### 3. Descarga del Repositorio
- ‚úÖ Clona el repositorio desde GitHub
- ‚úÖ Ubicaci√≥n: `/opt/TVA/`
- ‚úÖ Verifica la estructura del proyecto
- ‚úÖ Valida archivos cr√≠ticos

### 4. Ejecuci√≥n del Despliegue
- ‚úÖ Ejecuta `deploy_production.sh` autom√°ticamente
- ‚úÖ Instala Ollama
- ‚úÖ Descarga modelo base `gpt-oss:20b`
- ‚úÖ Crea modelo personalizado `aztecai`
- ‚úÖ Instala OpenWebUI con Docker
- ‚úÖ Configura servicios systemd

### 5. Verificaci√≥n Final
- ‚úÖ Muestra informaci√≥n de acceso
- ‚úÖ Proporciona comandos √∫tiles
- ‚úÖ Indica pr√≥ximos pasos

---

## üñ•Ô∏è Requisitos del Servidor

### Hardware M√≠nimo
| Componente | M√≠nimo | Recomendado |
|------------|---------|-------------|
| **CPU** | 8 cores | 16+ cores |
| **RAM** | 32 GB | 64 GB |
| **Almacenamiento** | 100 GB SSD | 500 GB NVMe |
| **GPU** | Opcional | NVIDIA 16GB+ |

### Software
- **Sistema Operativo:** Ubuntu 22.04 LTS (recomendado)
- **Acceso:** root o sudo
- **Conexi√≥n:** Internet estable (solo durante instalaci√≥n)

### Puertos Requeridos
- **3000** - OpenWebUI (interfaz web)
- **11434** - Ollama (API del modelo)
- **443** - HTTPS (producci√≥n, opcional)

---

## üìÇ Estructura Despu√©s de la Instalaci√≥n

```
/opt/TVA/
‚îî‚îÄ‚îÄ AztecAI_Model_V1/
    ‚îú‚îÄ‚îÄ 01_Documentacion/          # Documentaci√≥n completa
    ‚îú‚îÄ‚îÄ 02_Modelfiles/             # Configuraci√≥n del modelo
    ‚îÇ   ‚îî‚îÄ‚îÄ Modelfile.AztecAI.Professional
    ‚îú‚îÄ‚îÄ 03_Knowledge_Base/         # Base de conocimiento
    ‚îÇ   ‚îî‚îÄ‚îÄ AztecAI_Complete_Knowledge_Base.md
    ‚îú‚îÄ‚îÄ 04_Scripts/                # Scripts de instalaci√≥n
    ‚îÇ   ‚îú‚îÄ‚îÄ deploy_production.sh   # Script principal
    ‚îÇ   ‚îî‚îÄ‚îÄ verify_installation.sh # Verificaci√≥n
    ‚îú‚îÄ‚îÄ 05_Configuracion/          # Configuraciones
    ‚îî‚îÄ‚îÄ 06_Tests/                  # Tests de validaci√≥n
```

---

## ‚úÖ Verificaci√≥n de la Instalaci√≥n

Despu√©s de que el script termine, verifica que todo funcione correctamente:

### 1. Ejecutar Script de Verificaci√≥n

```bash
cd /opt/TVA/AztecAI_Model_V1/04_Scripts
./verify_installation.sh
```

### 2. Verificar Servicios Manualmente

```bash
# Verificar Ollama
systemctl status ollama
ollama list

# Verificar OpenWebUI
docker ps | grep open-webui

# Probar el modelo
ollama run aztecai "Hola, ¬øqui√©n eres?"
```

### 3. Acceder a la Interfaz Web

Abre tu navegador y accede a:
```
http://[IP_DEL_SERVIDOR]:3000
```

---

## üîß Configuraci√≥n Post-Instalaci√≥n

### 1. Crear Usuario Administrador en OpenWebUI

1. Accede a `http://[IP_DEL_SERVIDOR]:3000`
2. Crea la primera cuenta (ser√° administrador autom√°ticamente)
3. Configura nombre de usuario y contrase√±a

### 2. Importar Knowledge Base

1. En OpenWebUI, ve a **Workspace ‚Üí Documents**
2. Click en **"Upload Document"**
3. Selecciona: `/opt/TVA/AztecAI_Model_V1/03_Knowledge_Base/AztecAI_Complete_Knowledge_Base.md`
4. Espera a que se procese el documento

### 3. Configurar RAG (Retrieval-Augmented Generation)

1. Ve a **Workspace ‚Üí Collections**
2. Crea una nueva colecci√≥n llamada **"AztecAI"** (exactamente as√≠)
3. Agrega el documento de Knowledge Base a la colecci√≥n
4. Configura:
   - **Top-K:** 5
   - **Similarity Threshold:** 0.7

### 4. Seleccionar el Modelo

1. En el chat, selecciona el modelo **"aztecai"**
2. Activa la colecci√≥n **"AztecAI"** para usar RAG
3. Realiza una pregunta de prueba

---

## üß™ Pruebas de Validaci√≥n

### Prueba 1: Respuesta B√°sica
```
Pregunta: "¬øQui√©n eres?"
Esperado: Respuesta en espa√±ol, formato profesional
```

### Prueba 2: Informaci√≥n Corporativa (RAG)
```
Pregunta: "¬øCu√°l es la misi√≥n de TV Azteca?"
Esperado: Informaci√≥n extra√≠da del Knowledge Base
```

### Prueba 3: Formato Profesional
```
Pregunta: "Explica qu√© es la inteligencia artificial"
Esperado: Formato "Pir√°mide Invertida" con secciones claras
```

---

## üîÑ Actualizaci√≥n del Sistema

### Actualizar Knowledge Base (Sin Downtime)

```bash
# 1. Editar el archivo
vim /opt/TVA/AztecAI_Model_V1/03_Knowledge_Base/AztecAI_Complete_Knowledge_Base.md

# 2. Re-importar en OpenWebUI
# Interface ‚Üí Workspace ‚Üí Documents ‚Üí Replace
```

### Actualizar Modelo (Downtime 2-5 min)

```bash
# 1. Editar Modelfile
vim /opt/TVA/AztecAI_Model_V1/02_Modelfiles/Modelfile.AztecAI.Professional

# 2. Recrear modelo
cd /opt/TVA/AztecAI_Model_V1/02_Modelfiles
ollama create aztecai -f Modelfile.AztecAI.Professional

# 3. Reiniciar OpenWebUI
docker restart open-webui
```

### Actualizar desde GitHub

```bash
# 1. Ir al directorio del repositorio
cd /opt/TVA

# 2. Hacer pull de los √∫ltimos cambios
git pull origin main

# 3. Re-ejecutar despliegue si es necesario
cd AztecAI_Model_V1/04_Scripts
sudo ./deploy_production.sh
```

---

## üêõ Troubleshooting

### Problema: "Error al clonar el repositorio"

**Soluci√≥n:**
```bash
# Verificar conexi√≥n a GitHub
ping github.com

# Verificar que Git est√© instalado
git --version

# Clonar manualmente
cd /opt
git clone https://github.com/MLeon28/TVA.git
```

### Problema: "Puerto 3000 ya est√° en uso"

**Soluci√≥n:**
```bash
# Ver qu√© est√° usando el puerto
sudo lsof -i :3000

# Detener el servicio conflictivo
sudo systemctl stop [servicio]

# O cambiar el puerto en el script
```

### Problema: "Modelo no responde"

**Soluci√≥n:**
```bash
# Verificar que Ollama est√© corriendo
systemctl status ollama

# Reiniciar Ollama
sudo systemctl restart ollama

# Verificar logs
journalctl -u ollama -f
```

### Problema: "OpenWebUI no inicia"

**Soluci√≥n:**
```bash
# Ver logs del contenedor
docker logs open-webui

# Reiniciar contenedor
docker restart open-webui

# Recrear contenedor
docker stop open-webui
docker rm open-webui
cd /opt/TVA/AztecAI_Model_V1/04_Scripts
sudo ./deploy_production.sh
```

---

## üìû Soporte

### Documentaci√≥n Completa
Consulta la documentaci√≥n detallada en:
```
/opt/TVA/AztecAI_Model_V1/01_Documentacion/
```

Archivos importantes:
- **00_INICIO_AQUI.md** - Gu√≠a de inicio
- **GUIA_INSTALACION_SERVIDOR.md** - Instalaci√≥n manual
- **TROUBLESHOOTING_PRODUCCION.md** - Soluci√≥n de problemas
- **ARQUITECTURA_TECNICA.md** - Arquitectura del sistema

### Logs del Sistema
```bash
# Logs de Ollama
journalctl -u ollama -f

# Logs de OpenWebUI
docker logs -f open-webui

# Logs del sistema
journalctl -xe
```

---

## üéØ Checklist de Instalaci√≥n Exitosa

- [ ] Script de instalaci√≥n ejecutado sin errores
- [ ] Ollama instalado y corriendo
- [ ] Modelo `gpt-oss:20b` descargado
- [ ] Modelo `aztecai` creado
- [ ] OpenWebUI accesible en puerto 3000
- [ ] Usuario administrador creado
- [ ] Knowledge Base importado
- [ ] Colecci√≥n "AztecAI" configurada con RAG
- [ ] Pruebas de validaci√≥n exitosas
- [ ] Formato profesional funcionando
- [ ] RAG recuperando informaci√≥n correctamente

---

## üìä M√©tricas Esperadas

Despu√©s de la instalaci√≥n, deber√≠as ver:

- **Primera respuesta:** 3-7 segundos
- **Streaming start:** 1-2 segundos
- **Tokens/segundo:** 12-15
- **KB retrieval:** <1 segundo
- **Uso RAM:** 16-18GB por sesi√≥n

---

## üîí Seguridad

### Recomendaciones Post-Instalaci√≥n

1. **Configurar Firewall**
   ```bash
   sudo ufw allow 3000/tcp
   sudo ufw allow 443/tcp
   sudo ufw enable
   ```

2. **Configurar HTTPS con Nginx**
   - Ver: `/opt/TVA/AztecAI_Model_V1/05_Configuracion/nginx.conf`

3. **Configurar Autenticaci√≥n Corporativa**
   - Integrar con LDAP/SSO de TV Azteca

4. **Backups Autom√°ticos**
   ```bash
   # Backup de configuraci√≥n
   cd /opt/TVA/AztecAI_Model_V1/04_Scripts
   ./backup_config.sh
   ```

---

## ‚ú® Pr√≥ximos Pasos

Una vez instalado:

1. **D√≠a 1:** Validaci√≥n inicial con usuarios piloto
2. **Semana 1:** Estabilizaci√≥n y ajustes
3. **Semana 2-4:** Rollout progresivo
4. **Continuo:** Mantenimiento y actualizaciones

---

**√öltima actualizaci√≥n:** 6 de Noviembre 2025  
**Versi√≥n:** 1.0  
**Estado:** ‚úÖ Listo para Uso

---

*AztecAI - Powered by TV Azteca / Grupo Salinas* üá≤üáΩ

