# ğŸ¯ COMPARACIÃ“N DE MODELOS BASE PARA AZTECAI

## ğŸ“Š TABLA COMPARATIVA RÃPIDA

| Modelo | TamaÃ±o | Context | VRAM | EspaÃ±ol | Razonamiento | Velocidad | RecomendaciÃ³n |
|--------|--------|---------|------|---------|--------------|-----------|---------------|
| **qwen2.5:32b** â­ | 19 GB | 32K | 16 GB | â­â­â­â­â­ | â­â­â­â­â­ | â­â­â­â­ | **MEJOR OPCIÃ“N** |
| llama3.3:70b | 40 GB | 128K | 40 GB | â­â­â­â­ | â­â­â­â­â­ | â­â­â­ | MÃ¡ximo rendimiento |
| mistral-large | 80 GB | 128K | 48 GB | â­â­â­â­â­ | â­â­â­â­ | â­â­ | Contexto extenso |
| llama3.2:latest | 7 GB | 128K | 8 GB | â­â­â­ | â­â­â­ | â­â­â­â­â­ | Recursos limitados |
| qwen2.5:14b | 9 GB | 32K | 10 GB | â­â­â­â­ | â­â­â­â­ | â­â­â­â­ | Alternativa ligera |

---

## ğŸ† OPCIÃ“N 1: QWEN2.5:32B (RECOMENDADO) â­

### âœ… Ventajas

**1. Excelente en EspaÃ±ol**
- Entrenado especÃ­ficamente con corpus en espaÃ±ol de alta calidad
- Comprende modismos mexicanos y lenguaje corporativo
- Genera texto natural sin anglicismos

**2. Razonamiento Superior**
- Arquitectura optimizada para tareas analÃ­ticas
- Excelente en seguimiento de instrucciones complejas
- Manejo robusto de reglas y restricciones (ideal para las 10 reglas inmutables)

**3. Context Window Adecuado**
- 32K tokens nativos (suficiente para los 3 documentos .md optimizados)
- No requiere tÃ©cnicas de compresiÃ³n
- Mantiene coherencia en conversaciones largas

**4. Recursos Razonables**
- 19 GB de almacenamiento
- 16 GB VRAM mÃ­nima (accesible en GPUs modernas)
- Velocidad de inferencia aceptable

**5. Licencia Permisiva**
- Apache 2.0
- Uso comercial permitido
- Sin restricciones para uso corporativo

### âŒ Desventajas

- Context window menor que Llama 3.3 (32K vs 128K)
- Menos conocido que modelos de Meta/Mistral
- Requiere GPU dedicada para rendimiento Ã³ptimo

### ğŸ¯ Casos de Uso Ideales

- âœ… Respuestas corporativas en espaÃ±ol
- âœ… AnÃ¡lisis de datos y reportes
- âœ… GeneraciÃ³n de contenido comercial
- âœ… Asistencia operativa diaria
- âœ… Seguimiento estricto de polÃ­ticas

### ğŸ“ Comando de InstalaciÃ³n

```bash
ollama pull qwen2.5:32b
ollama create aztecai:full -f Modelfile.AztecAI.optimized
```

---

## ğŸš€ OPCIÃ“N 2: LLAMA 3.3:70B (MÃXIMO RENDIMIENTO)

### âœ… Ventajas

**1. Mejor Modelo Open-Source Disponible**
- Rendimiento comparable a GPT-4 en muchas tareas
- Arquitectura probada y optimizada
- Amplio soporte de la comunidad

**2. Context Window Masivo**
- 128K tokens (4x mÃ¡s que Qwen)
- Permite incluir documentaciÃ³n extensa sin optimizar
- Ideal para anÃ¡lisis de documentos largos

**3. Razonamiento de Clase Mundial**
- Excelente en tareas complejas
- Capacidad de seguir cadenas de razonamiento largas
- Manejo superior de ambigÃ¼edades

**4. MultilingÃ¼e Robusto**
- Buen desempeÃ±o en espaÃ±ol (aunque no especializado)
- Capacidad de traducciÃ³n integrada
- ComprensiÃ³n contextual profunda

### âŒ Desventajas

- **Requiere 40+ GB VRAM** (GPU de gama alta o mÃºltiples GPUs)
- 40 GB de almacenamiento
- Inferencia mÃ¡s lenta que modelos pequeÃ±os
- Mayor consumo energÃ©tico

### ğŸ¯ Casos de Uso Ideales

- âœ… AnÃ¡lisis estratÃ©gico complejo
- âœ… GeneraciÃ³n de reportes ejecutivos extensos
- âœ… InvestigaciÃ³n y sÃ­ntesis de informaciÃ³n
- âœ… Tareas que requieren razonamiento profundo
- âœ… Cuando el hardware no es limitante

### ğŸ“ Comando de InstalaciÃ³n

```bash
ollama pull llama3.3:70b

# Editar Modelfile.AztecAI.optimized lÃ­nea 20:
# FROM llama3.3:70b

# Opcional: aumentar context window
# PARAMETER num_ctx 131072  # 128K
```

---

## ğŸŒ OPCIÃ“N 3: MISTRAL-LARGE (EQUILIBRIO)

### âœ… Ventajas

**1. Excelente en EspaÃ±ol**
- Desarrollado por empresa europea (Mistral AI)
- Fuerte Ã©nfasis en idiomas europeos y espaÃ±ol
- GeneraciÃ³n de texto muy natural

**2. Context Window Extenso**
- 128K tokens
- Manejo eficiente de contexto largo
- Buena retenciÃ³n de informaciÃ³n

**3. Licencia Comercial Clara**
- DiseÃ±ado para uso empresarial
- Soporte oficial disponible
- Actualizaciones regulares

### âŒ Desventajas

- **80+ GB de almacenamiento** (el mÃ¡s grande)
- Requiere 48+ GB VRAM
- Inferencia lenta
- Menos optimizado para hardware consumer

### ğŸ¯ Casos de Uso Ideales

- âœ… Cuando el espaÃ±ol es crÃ­tico
- âœ… DocumentaciÃ³n muy extensa
- âœ… Entorno enterprise con hardware dedicado
- âœ… Necesidad de soporte oficial

### ğŸ“ Comando de InstalaciÃ³n

```bash
ollama pull mistral-large:latest

# Editar Modelfile.AztecAI.optimized lÃ­nea 20:
# FROM mistral-large:latest
```

---

## ğŸ’¡ OPCIÃ“N 4: LLAMA3.2:LATEST (RECURSOS LIMITADOS)

### âœ… Ventajas

**1. Muy Ligero**
- Solo 7 GB de almacenamiento
- 8 GB VRAM suficiente
- Puede correr en laptops modernas

**2. RÃ¡pido**
- Inferencia muy veloz
- Baja latencia
- Ideal para respuestas inmediatas

**3. Context Window Grande**
- 128K tokens (sorprendente para su tamaÃ±o)
- Buena relaciÃ³n tamaÃ±o/capacidad

### âŒ Desventajas

- Capacidades limitadas vs modelos grandes
- EspaÃ±ol menos robusto
- Razonamiento mÃ¡s bÃ¡sico
- Puede "alucinar" mÃ¡s frecuentemente

### ğŸ¯ Casos de Uso Ideales

- âœ… Prototipado rÃ¡pido
- âœ… Testing del Modelfile
- âœ… Hardware limitado
- âœ… Respuestas simples y directas

### ğŸ“ Comando de InstalaciÃ³n

```bash
ollama pull llama3.2:latest

# Editar Modelfile.AztecAI.optimized lÃ­nea 20:
# FROM llama3.2:latest

# Reducir parÃ¡metros:
# PARAMETER num_ctx 8192
# PARAMETER num_predict 2048
```

---

## ğŸ¯ RECOMENDACIÃ“N FINAL

### Para TV Azteca (ProducciÃ³n): **QWEN2.5:32B** â­

**Razones:**

1. **EspaÃ±ol nativo de calidad** â†’ CrÃ­tico para comunicaciÃ³n corporativa
2. **Recursos razonables** â†’ Deployable en hardware estÃ¡ndar enterprise
3. **Razonamiento robusto** â†’ Maneja las 10 reglas inmutables perfectamente
4. **Context adecuado** â†’ 32K suficiente con documentos optimizados
5. **Velocidad aceptable** â†’ Respuestas en tiempo razonable

### Para Testing/Desarrollo: **LLAMA3.2:LATEST**

- RÃ¡pido para iterar
- Bajo costo de recursos
- FÃ¡cil de desplegar

### Para Casos Especiales: **LLAMA3.3:70B**

- AnÃ¡lisis estratÃ©gico complejo
- Reportes ejecutivos extensos
- Cuando se dispone de GPU de gama alta

---

## ğŸ“Š MATRIZ DE DECISIÃ“N

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SI TIENES...              â”‚ USA...                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ GPU 16GB+ y necesitas     â”‚ qwen2.5:32b â­                  â”‚
â”‚ espaÃ±ol de calidad        â”‚                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ GPU 40GB+ y necesitas     â”‚ llama3.3:70b                    â”‚
â”‚ mÃ¡ximo rendimiento        â”‚                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Ã‰nfasis en espaÃ±ol y      â”‚ mistral-large                   â”‚
â”‚ hardware enterprise       â”‚                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ GPU 8GB o menos           â”‚ llama3.2:latest                 â”‚
â”‚ (testing/desarrollo)      â”‚                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

**VersiÃ³n:** 1.0.0  
**Fecha:** Enero 2026  
**Autor:** Ãrea de Inteligencia Artificial Azteca

